---
title: "Architecture"
description-meta: "More about the architecture of Magasin architecture"
format: html
---

Magasin is a scalable end-to-end data platform based on open-source components that is natively run in a [Kubernetes cluster](https://kubernetes.io).

By end-to-end this describes a data processing pipeline including from how to ingest raw data from multiple data sources, transform the data, run analyses on the processed data, storage in a cloud or local filesystem to enabling visualisation.

Kubernetes is a container orchestration system designed to automate the deployment, scaling, and management of [containerized applications](https://kubernetes.io/docs/concepts/overview/#going-back-in-time). It is an integral part of services offered by major cloud providers. Kubernetes, being open source, can also be set up on-premises. For testing purposes, it is even possible to install it on a desktop computer.

Magasin uses Kubernetes in combination with [Helm](https://helm.sh/), a package manager for Kubernetes applications. Helm is the equivalent to apt, pip, npm, pacman, snap, conda.. Using Helm, users specify the configuration of required Kubernetes resources to deploy magasin through a values file or command-line overrides. A package in helm is called a **chart**.

A fundamental contrast between Magasin and other helm-based Kubernetes applications lies in their architectural approach. Typically, an application is characterized by a sole root helm chart governing all deployment rules. However, in Magasin, each component operates as an autonomous helm chart. This design choice enables the establishment of a loosely-coupled architecture among its components. Rather than mandating a rigid structure for the entire architecture, Magasin embraces a more open and modular approach, fostering flexibility in component selection and integration. 

The core components of Magasin are independent mature open source projects that support.

# Underlying technologies

## Kubernetes containerization 
Kubernetes is a container orchestration system designed to automate the deployment, scaling, and management of [containerized applications](https://kubernetes.io/docs/concepts/overview/#going-back-in-time). It is an integral part of services offered by major cloud providers. Kubernetes, being open source, can also be set up on-premises. For testing purposes, it is even possible to install it on a desktop computer.

## Helm charts 
Magasin uses Kubernetes in combination with [Helm](https://helm.sh/), a package manager for Kubernetes applications. Helm is the equivalent to apt, pip, npm, pacman, snap, conda, etc. Using Helm, users specify the configuration of required Kubernetes resources to deploy magasin through a values file or command-line overrides. A package in helm is called **chart**.


## Loosely-coupled architecture

A fundamental contrast between magasin and other helm-based Kubernetes applications lies in their architectural approach. Typically, an application is characterized by a sole root helm chart governing all deployment rules. However, in magasin, each component operates as an autonomous helm chart. This design choice enables the establishment of a loosely-coupled architecture among its components. Rather than mandating a rigid structure for the entire architecture, magasin embraces a more open and adaptable approach, fostering flexibility in component selection and integration.


# Core components 

## Ingestion: Dagster
The [Dagster](http://dagster.io) framework is the primary tool for orchestration of data pipelines for ingestion, transformation, analysis, and machine learning. Each pipeline is isolated and encapsulated, so different tasks may utilize different versions of the same library, for example, and each pipeline run is executed in a short-lived pod on a Kubernetes cluster.

###  Dagit
Dagster's Dagit UI provides visibility of pipelines' tasks, scheduling, run status, materialized assets, resources, and modes.


## Cloud storage: MinIO

MinIO is an open-source, high-performance object storage system designed for cloud-native and containerized applications. Founded in 2014, MinIO offers an S3-compatible API, enabling seamless integration with existing cloud storage ecosystems. It is known for its simplicity, scalability, and speed, making it a popular choice for organizations seeking efficient data storage solutions. MinIO's architecture is optimized for modern data workloads, leveraging erasure coding and distributed techniques to ensure data resilience and high availability. With its lightweight footprint and easy deployment on standard hardware, MinIO empowers developers to build scalable storage infrastructures tailored to their specific needs, whether for on-premises, hybrid, or multi-cloud environments.

## Query engine: Apache Drill

[Apache Drill](https://drill.apache.org/) is an open-source, schema-free query engine that provides a SQL interface to a wide range of non-relational datastores, such as NoSQL databases and collections of files such as JSON, CSV, ESRI shapefiles, SPSS & SAS formats, Parquet, and others.

While [data marts](https://en.wikipedia.org/wiki/Data_mart) for specific business functions or locations traditionally require hosting and maintenance of a relational database on a server or virtual machine, Apache Drill enables comparable functionality without need for running and hosting a database or maintaining schema changes from source systems over time. 

Instead, a Dagster ingestion and transformation pipeline stores an 'analyst-ready' dataset that Apache Drill can query directly.

## Dashboards: Apache Superset
[Apache Superset](https://superset.apache.org/) is an open-source business intelligence product with comprehensive charting, dashboarding, and querying capabilities.

## Notebook environment: Daskhub
[Daskhub](https://blog.dask.org/2020/08/31/helm_daskhub) is a [Helm chart](https://helm.dask.org/) to easily install JupyterHub and Dask Gateway for multiple users on a Kubernetes cluster.

### JupyterHub
The multi-tenant JupyterHub component creates on-demand, isolated pods for authenticated users, each with persistent storage for their R and Python notebook workspace. 

### Dask Gateway
Dask Gateway allows easy utilization of a Dask cluster from notebook environments for distributed computation of massive datasets or parallelizable operations.

